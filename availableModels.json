{
  "vosk-model-small-en-us-0.15": [
    "https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip",
    "40M",
    "9.85 (librispeech test-clean) 10.38 (tedlium)",
    "Lightweight wideband model for Android and RPi",
    "Apache 2.0"
  ],
  "vosk-model-en-us-0.22": [
    "https://alphacephei.com/vosk/models/vosk-model-en-us-0.22.zip",
    "1.8G",
    "5.69 (librispeech test-clean) 6.05 (tedlium) 29.78(callcenter)",
    "Accurate generic US English model",
    "Apache 2.0"
  ],
  "vosk-model-en-us-0.22-lgraph": [
    "https://alphacephei.com/vosk/models/vosk-model-en-us-0.22-lgraph.zip",
    "128M",
    "7.82 (librispeech) 8.20 (tedlium)",
    "Big US English model with dynamic graph",
    "Apache 2.0"
  ],
  "vosk-model-en-us-0.42-gigaspeech": [
    "https://alphacephei.com/vosk/models/vosk-model-en-us-0.42-gigaspeech.zip",
    "2.3G",
    "5.64 (librispeech test-clean) 6.24 (tedlium) 30.17 (callcenter)",
    "Accurate generic US English model trained by Kaldi on Gigaspeech. Mostly for podcasts, not for telephony",
    "Apache 2.0"
  ],
  "vosk-model-en-us-daanzu-20200905": [
    "https://alphacephei.com/vosk/models/vosk-model-en-us-daanzu-20200905.zip",
    "1.0G",
    "7.08 (librispeech test-clean)  8.25 (tedlium)",
    "Wideband model for dictation from Kaldi-active-grammar project",
    "AGPL"
  ],
  "vosk-model-en-us-daanzu-20200905-lgraph": [
    "https://alphacephei.com/vosk/models/vosk-model-en-us-daanzu-20200905-lgraph.zip",
    "129M",
    "8.20 (librispeech test-clean) 9.28 (tedlium)",
    "Wideband model for dictation from Kaldi-active-grammar project with configurable graph",
    "AGPL"
  ],
  "vosk-model-en-us-librispeech-0.2": [
    "https://alphacephei.com/vosk/models/vosk-model-en-us-librispeech-0.2.zip",
    "845M",
    "TBD",
    "Repackaged Librispeech model from Kaldi, not very accurate",
    "Apache 2.0"
  ],
  "vosk-model-small-en-us-zamia-0.5": [
    "https://alphacephei.com/vosk/models/vosk-model-small-en-us-zamia-0.5.zip",
    "49M",
    "11.55 (librispeech test-clean) 12.64 (tedlium)",
    "Repackaged Zamia model f_250, mainly for research",
    "LGPL-3.0"
  ],
  "vosk-model-en-us-aspire-0.2": [
    "https://alphacephei.com/vosk/models/vosk-model-en-us-aspire-0.2.zip",
    "1.4G",
    "13.64 (librispeech test-clean) 12.89 (tedlium) 33.82(callcenter)",
    "Kaldi original ASPIRE model, not very accurate",
    "Apache 2.0"
  ],
  "vosk-model-en-us-0.21": [
    "https://alphacephei.com/vosk/models/vosk-model-en-us-0.21.zip",
    "1.6G",
    "5.43 (librispeech test-clean) 6.42 (tedlium) 40.63(callcenter)",
    "Wideband model previous generation",
    "Apache 2.0"
  ],
  "vosk-model-en-in-0.5": [
    "https://alphacephei.com/vosk/models/vosk-model-en-in-0.5.zip",
    "1G",
    "36.12 (NPTEL Pure)",
    "Generic Indian English model for telecom and broadcast",
    "Apache 2.0"
  ],
  "vosk-model-small-en-in-0.4": [
    "https://alphacephei.com/vosk/models/vosk-model-small-en-in-0.4.zip",
    "36M",
    "49.05 (NPTEL Pure)",
    "Lightweight Indian English model for mobile applications",
    "Apache 2.0"
  ],
  "vosk-model-small-cn-0.22": [
    "https://alphacephei.com/vosk/models/vosk-model-small-cn-0.22.zip",
    "42M",
    "23.54 (SpeechIO-02) 38.29 (SpeechIO-06) 17.15 (THCHS)",
    "Lightweight model for Android and RPi",
    "Apache 2.0"
  ],
  "vosk-model-cn-0.22": [
    "https://alphacephei.com/vosk/models/vosk-model-cn-0.22.zip",
    "1.3G",
    "13.98 (SpeechIO-02) 27.30 (SpeechIO-06) 7.43 (THCHS)",
    "Big generic Chinese model for server processing",
    "Apache 2.0"
  ],
  "vosk-model-cn-kaldi-multicn-0.15": [
    "https://alphacephei.com/vosk/models/vosk-model-cn-kaldi-multicn-0.15.zip",
    "1.5G",
    "17.44 (SpeechIO-02) 9.56 (THCHS)",
    "Original Wideband Kaldi multi-cn model from Kaldi with Vosk LM",
    "Apache 2.0"
  ],
  "vosk-model-ru-0.42": [
    "https://alphacephei.com/vosk/models/vosk-model-ru-0.42.zip",
    "1.8G",
    "4.5 (our audiobooks) 11.1 (open_stt audiobooks) 19.5 (open_stt youtube) 36.0 (openstt calls) 4.4 (golos crowd) 17.9 (sova devices)",
    "Big mixed band Russian model for servers",
    "Apache 2.0"
  ],
  "vosk-model-small-ru-0.22": [
    "https://alphacephei.com/vosk/models/vosk-model-small-ru-0.22.zip",
    "45M",
    "22.71 (openstt audiobooks) 31.97 (openstt youtube) 29.89 (sova devices) 11.79 (golos crowd)",
    "Lightweight wideband model for Android/iOS and RPi",
    "Apache 2.0"
  ],
  "vosk-model-ru-0.22": [
    "https://alphacephei.com/vosk/models/vosk-model-ru-0.22.zip",
    "1.5G",
    "5.74 (our audiobooks) 13.35 (open_stt audiobooks) 20.73 (open_stt youtube) 37.38 (openstt calls) 8.65 (golos crowd) 19.71 (sova devices)",
    "Big mixed band Russian model for servers",
    "Apache 2.0"
  ],
  "vosk-model-ru-0.10": [
    "https://alphacephei.com/vosk/models/vosk-model-ru-0.10.zip",
    "2.5G",
    "5.71 (our audiobooks) 16.26 (open_stt audiobooks) 26.20 (public_youtube_700_val open_stt) 40.15 (asr_calls_2_val open_stt)",
    "Big narrowband Russian model for servers",
    "Apache 2.0"
  ],
  "vosk-model-small-fr-0.22": [
    "https://alphacephei.com/vosk/models/vosk-model-small-fr-0.22.zip",
    "41M",
    "23.95 (cv test) 19.30 (mtedx) 27.25 (podcast)",
    "Lightweight wideband model for Android/iOS and RPi",
    "Apache 2.0"
  ],
  "vosk-model-fr-0.22": [
    "https://alphacephei.com/vosk/models/vosk-model-fr-0.22.zip",
    "1.4G",
    "14.72 (cv test) 11.64 (mls) 13.10 (mtedx) 21.61 (podcast) 13.22 (voxpopuli)",
    "Big accurate model for servers",
    "Apache 2.0"
  ],
  "vosk-model-small-fr-pguyot-0.3": [
    "https://alphacephei.com/vosk/models/vosk-model-small-fr-pguyot-0.3.zip",
    "39M",
    "37.04 (cv test) 28.72 (mtedx) 37.46 (podcast)",
    "Lightweight wideband model for Android and RPi trained by Paul Guyot",
    "CC-BY-NC-SA 4.0"
  ],
  "vosk-model-fr-0.6-linto-2.2.0": [
    "https://alphacephei.com/vosk/models/vosk-model-fr-0.6-linto-2.2.0.zip",
    "1.5G",
    "16.19 (cv test) 16.44 (mtedx) 23.77 (podcast) 0.4xRT",
    "Model from LINTO project",
    "AGPL"
  ],
  "vosk-model-de-0.21": [
    "https://alphacephei.com/vosk/models/vosk-model-de-0.21.zip",
    "1.9G",
    "9.83 (Tuda-de test), 24.00 (podcast) 12.82 (cv-test) 12.42 (mls) 33.26 (mtedx)",
    "Big German model for telephony and server",
    "Apache 2.0"
  ],
  "vosk-model-de-tuda-0.6-900k": [
    "https://alphacephei.com/vosk/models/vosk-model-de-tuda-0.6-900k.zip",
    "4.4G",
    "9.48 (Tuda-de test), 25.82 (podcast) 4.97 (cv-test) 11.01 (mls) 35.20 (mtedx)",
    "Latest big wideband model from Tuda-DE project",
    "Apache 2.0"
  ],
  "vosk-model-small-de-zamia-0.3": [
    "https://alphacephei.com/vosk/models/vosk-model-small-de-zamia-0.3.zip",
    "49M",
    "14.81 (Tuda-de test, 37.46 (podcast)",
    "Zamia f_250 small model repackaged (not recommended)",
    "LGPL-3.0"
  ],
  "vosk-model-small-de-0.15": [
    "https://alphacephei.com/vosk/models/vosk-model-small-de-0.15.zip",
    "45M",
    "13.75 (Tuda-de test), 30.67 (podcast)",
    "Lightweight wideband model for Android and RPi",
    "Apache 2.0"
  ],
  "vosk-model-small-es-0.42": [
    "https://alphacephei.com/vosk/models/vosk-model-small-es-0.42.zip",
    "39M",
    "16.02 (cv test) 16.72 (mtedx test) 11.21 (mls)",
    "Lightweight wideband model for Android and RPi",
    "Apache 2.0"
  ],
  "vosk-model-es-0.42": [
    "https://alphacephei.com/vosk/models/vosk-model-es-0.42.zip",
    "1.4G",
    "7.50 (cv test) 10.05 (mtedx test) 5.84 (mls)",
    "Big model for Spanish",
    "Apache 2.0"
  ],
  "vosk-model-small-pt-0.3": [
    "https://alphacephei.com/vosk/models/vosk-model-small-pt-0.3.zip",
    "31M",
    "68.92 (coraa dev) 32.60 (cv test)",
    "Lightweight wideband model for Android and RPi",
    "Apache 2.0"
  ],
  "vosk-model-pt-fb-v0.1.1-20220516_2113": [
    "https://alphacephei.com/vosk/models/vosk-model-pt-fb-v0.1.1-20220516_2113.zip",
    "1.6G",
    "54.34 (coraa dev) 27.70 (cv test)",
    "Big model from FalaBrazil",
    "GPLv3.0"
  ],
  "vosk-model-el-gr-0.7": [
    "https://alphacephei.com/vosk/models/vosk-model-el-gr-0.7.zip",
    "1.1G",
    "TBD",
    "Big narrowband Greek model for server processing, not extremely accurate though",
    "Apache 2.0"
  ],
  "vosk-model-small-tr-0.3": [
    "https://alphacephei.com/vosk/models/vosk-model-small-tr-0.3.zip",
    "35M",
    "TBD",
    "Lightweight wideband model for Android and RPi",
    "Apache 2.0"
  ],
  "vosk-model-small-vn-0.4": [
    "https://alphacephei.com/vosk/models/vosk-model-small-vn-0.4.zip",
    "32M",
    "15.70 (Vivos test)",
    "Lightweight Vietnamese model",
    "Apache 2.0"
  ],
  "vosk-model-vn-0.4": [
    "https://alphacephei.com/vosk/models/vosk-model-vn-0.4.zip",
    "78M",
    "15.70 (Vivos test)",
    "Bigger Vietnamese model for server",
    "Apache 2.0"
  ],
  "vosk-model-small-it-0.22": [
    "https://alphacephei.com/vosk/models/vosk-model-small-it-0.22.zip",
    "48M",
    "16.88 (cv test) 25.87 (mls) 17.01 (mtedx)",
    "Lightweight model for Android and RPi",
    "Apache 2.0"
  ],
  "vosk-model-it-0.22": [
    "https://alphacephei.com/vosk/models/vosk-model-it-0.22.zip",
    "1.2G",
    "8.10 (cv test) 15.68 (mls) 11.23 (mtedx)",
    "Big generic Italian model for servers",
    "Apache 2.0"
  ],
  "vosk-model-small-nl-0.22": [
    "https://alphacephei.com/vosk/models/vosk-model-small-nl-0.22.zip",
    "39M",
    "22.45 (cv test) 26.80 (tv) 25.84 (mls) 24.09 (voxpopuli)",
    "Lightweight model for Dutch",
    "Apache 2.0"
  ],
  "vosk-model-nl-spraakherkenning-0.6": [
    "https://alphacephei.com/vosk/models/vosk-model-nl-spraakherkenning-0.6.zip",
    "860M",
    "20.40 (cv test) 32.64 (tv) 17.73 (mls) 19.96 (voxpopuli)",
    "Medium Dutch model from Kaldi_NL",
    "CC-BY-NC-SA"
  ],
  "vosk-model-nl-spraakherkenning-0.6-lgraph": [
    "https://alphacephei.com/vosk/models/vosk-model-nl-spraakherkenning-0.6-lgraph.zip",
    "100M",
    "22.82 (cv test) 34.01 (tv) 18.81 (mls) 21.01 (voxpopuli)",
    "Smaller model with dynamic graph",
    "CC-BY-NC-SA"
  ],
  "vosk-model-small-ca-0.4": [
    "https://alphacephei.com/vosk/models/vosk-model-small-ca-0.4.zip",
    "42M",
    "TBD",
    "Lightweight wideband model for Android and RPi for Catalan",
    "Apache 2.0"
  ],
  "vosk-model-ar-mgb2-0.4": [
    "https://alphacephei.com/vosk/models/vosk-model-ar-mgb2-0.4.zip",
    "318M",
    "16.40 (MGB-2 dev set)",
    "Repackaged Arabic model trained on MGB2 dataset from Kaldi",
    "Apache 2.0"
  ],
  "vosk-model-ar-0.22-linto-1.1.0": [
    "https://alphacephei.com/vosk/models/vosk-model-ar-0.22-linto-1.1.0.zip",
    "1.3G",
    "52.87 (cv test) 28.50 (MBG-2 dev set) 1.0xRT",
    "Big model from LINTO project",
    "AGPL"
  ],
  "vosk-model-small-fa-0.4": [
    "https://alphacephei.com/vosk/models/vosk-model-small-fa-0.4.zip",
    "47M",
    "TBD",
    "Lightweight wideband model for Android and RPi for Farsi (Persian)",
    "Apache 2.0"
  ],
  "vosk-model-fa-0.5": [
    "https://alphacephei.com/vosk/models/vosk-model-fa-0.5.zip",
    "1G",
    "TBD",
    "Model with large vocabulary, not yet accurate but better than before (Persian)",
    "Apache 2.0"
  ],
  "vosk-model-small-fa-0.5": [
    "https://alphacephei.com/vosk/models/vosk-model-small-fa-0.5.zip",
    "60M",
    "TBD",
    "Bigger small model for desktop application (Persian)",
    "Apache 2.0"
  ],
  "vosk-model-tl-ph-generic-0.6": [
    "https://alphacephei.com/vosk/models/vosk-model-tl-ph-generic-0.6.zip",
    "320M",
    "TBD",
    "Medium wideband model for Filipino (Tagalog) by feddybear",
    "CC-BY-NC-SA 4.0"
  ],
  "vosk-model-small-uk-v3-nano": [
    "https://alphacephei.com/vosk/models/vosk-model-small-uk-v3-nano.zip",
    "73M",
    "TBD",
    "Nano model from Speech Recognition for Ukrainian",
    "Apache 2.0"
  ],
  "vosk-model-small-uk-v3-small": [
    "https://alphacephei.com/vosk/models/vosk-model-small-uk-v3-small.zip",
    "133M",
    "TBD",
    "Small model from Speech Recognition for Ukrainian",
    "Apache 2.0"
  ],
  "vosk-model-uk-v3": [
    "https://alphacephei.com/vosk/models/vosk-model-uk-v3.zip",
    "343M",
    "TBD",
    "Bigger model from Speech Recognition for Ukrainian",
    "Apache 2.0"
  ],
  "vosk-model-uk-v3-lgraph": [
    "https://alphacephei.com/vosk/models/vosk-model-uk-v3-lgraph.zip",
    "325M",
    "TBD",
    "Big dynamic model from Speech Recognition for Ukrainian",
    "Apache 2.0"
  ],
  "vosk-model-small-kz-0.15": [
    "https://alphacephei.com/vosk/models/vosk-model-small-kz-0.15.zip",
    "42M",
    "9.60(dev) 8.32(test)",
    "Small mobile model from SAIDA_Kazakh",
    "Apache 2.0"
  ],
  "vosk-model-kz-0.15": [
    "https://alphacephei.com/vosk/models/vosk-model-kz-0.15.zip",
    "378M",
    "8.06(dev) 6.81(test)",
    "Bigger wideband model SAIDA_Kazakh",
    "Apache 2.0"
  ],
  "vosk-model-small-sv-rhasspy-0.15": [
    "https://alphacephei.com/vosk/models/vosk-model-small-sv-rhasspy-0.15.zip",
    "289M",
    "TBD",
    "Repackaged model from Rhasspy project",
    "MIT"
  ],
  "vosk-model-small-ja-0.22": [
    "https://alphacephei.com/vosk/models/vosk-model-small-ja-0.22.zip",
    "48M",
    "9.52(csj CER) 17.07(ted10k CER)",
    "Lightweight wideband model for Japanese",
    "Apache 2.0"
  ],
  "vosk-model-ja-0.22": [
    "https://alphacephei.com/vosk/models/vosk-model-ja-0.22.zip",
    "1Gb",
    "8.40(csj CER) 13.91(ted10k CER)",
    "Big model for Japanese",
    "Apache 2.0"
  ],
  "vosk-model-small-eo-0.42": [
    "https://alphacephei.com/vosk/models/vosk-model-small-eo-0.42.zip",
    "42M",
    "7.24 (CV Test)",
    "Lightweight model for Esperanto",
    "Apache 2.0"
  ],
  "vosk-model-small-hi-0.22": [
    "https://alphacephei.com/vosk/models/vosk-model-small-hi-0.22.zip",
    "42M",
    "20.89 (IITM Challenge) 24.72 (MUCS Challenge)",
    "Lightweight model for Hindi",
    "Apache 2.0"
  ],
  "vosk-model-hi-0.22": [
    "https://alphacephei.com/vosk/models/vosk-model-hi-0.22.zip",
    "1.5Gb",
    "14.85 (CV Test) 14.83 (IITM Challenge) 13.11 (MUCS Challenge)",
    "Big accurate model for servers",
    "Apache 2.0"
  ],
  "vosk-model-small-cs-0.4-rhasspy": [
    "https://alphacephei.com/vosk/models/vosk-model-small-cs-0.4-rhasspy.zip",
    "44M",
    "21.29 (CV Test)",
    "Lightweight model for Czech from Rhasspy project",
    "MIT"
  ],
  "vosk-model-small-pl-0.22": [
    "https://alphacephei.com/vosk/models/vosk-model-small-pl-0.22.zip",
    "50M",
    "18.36 (CV Test) 16.88 (MLS Test) 11.55 (Voxpopuli Test)",
    "Lightweight model for Polish",
    "Apache 2.0"
  ],
  "vosk-model-small-uz-0.22": [
    "https://alphacephei.com/vosk/models/vosk-model-small-uz-0.22.zip",
    "49M",
    "13.54 (CV Test) 12.92 (IS2AI USC test)",
    "Lightweight model for Uzbek",
    "Apache 2.0"
  ],
  "vosk-model-small-ko-0.22": [
    "https://alphacephei.com/vosk/models/vosk-model-small-ko-0.22.zip",
    "82M",
    "28.1 (Zeroth Test)",
    "Lightweight model for Korean",
    "Apache 2.0"
  ],
  "vosk-model-br-0.8": [
    "https://alphacephei.com/vosk/models/vosk-model-br-0.8.zip",
    "70M",
    "36.4 (MCV11 Test)",
    "Breton model from vosk-br project",
    "MIT license"
  ],
  "vosk-model-gu-0.42": [
    "https://alphacephei.com/vosk/models/vosk-model-gu-0.42.zip",
    "700M",
    "16.45 (MS Test)",
    "Big Gujarati model",
    "Apache 2.0"
  ],
  "vosk-model-small-gu-0.42": [
    "https://alphacephei.com/vosk/models/vosk-model-small-gu-0.42.zip",
    "100M",
    "20.49 (MS Test)",
    "Lightweight model for Gujarati",
    "Apache 2.0"
  ],
  "vosk-model-spk-0.4": [
    "https://alphacephei.com/vosk/models/vosk-model-spk-0.4.zip",
    "13M",
    "TBD",
    "Model for speaker identification, should work for all languages",
    "Apache 2.0"
  ]
}
